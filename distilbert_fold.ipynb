{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86b86f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default GPU Device:/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import ktrain\n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:{}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50743ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import ktrain\n",
    "from ktrain import text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3adab8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "run_precision = []\n",
    "run_recall = []\n",
    "run_f1score = []\n",
    "run_accuracy = []\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=False, random_state=125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c240016",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('sstubsIn_edited.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce99cbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10231, 5)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d95d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"pre-processing train data...\")\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "raw_docs_train = data['sourceBeforeFix'].tolist()\n",
    "#raw_docs_test = test_data['message'].tolist() \n",
    "num_classes = 4\n",
    "\n",
    "\n",
    "word_seq_train = raw_docs_train\n",
    "word_seq_train = np.array(word_seq_train)\n",
    "\n",
    "#data.bugType.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "434bbc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0,1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1463cf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = {\n",
    "    'CHANGE_IDENTIFIER': 0, \n",
    "    'CHANGE_MODIFIER': 0,\n",
    "    'CHANGE_NUMERAL': 0, \n",
    "    'SWAP_BOOLEAN_LITERAL': 0,\n",
    "     'DIFFERENT_METHOD_SAME_ARGS': 1, \n",
    "     'OVERLOAD_METHOD_MORE_ARGS': 1, \n",
    "    'OVERLOAD_METHOD_DELETED_ARGS': 1,\n",
    "     'CHANGE_CALLER_IN_FUNCTION_CALL': 1, \n",
    "     'SWAP_ARGUMENTS': 1,\n",
    "     'CHANGE_OPERATOR': 2, \n",
    "    'CHANGE_UNARY_OPERATOR': 2, \n",
    "    'CHANGE_OPERAND': 2, \n",
    "     'LESS_SPECIFIC_IF': 3,\n",
    "    'MORE_SPECIFIC_IF': 3,\n",
    "     'ADD_THROWS_EXCEPTION': 3, \n",
    "      'DELETE_THROWS_EXCEPTION':3,\n",
    "       \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cff52e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_initial= data['bugType'].values\n",
    "\n",
    "\n",
    "y_train_initial = [encoding[x] for x in y_train_initial]\n",
    "y_train_initial=np.array(y_train_initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fe399e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "t = text.Transformer(MODEL_NAME, maxlen=150, class_names=class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "424b03a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold  1\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 4\n",
      "\t95percentile : 9\n",
      "\t99percentile : 33\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 5\n",
      "\t95percentile : 8\n",
      "\t99percentile : 35\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 3\n",
      "\t95percentile : 8\n",
      "\t99percentile : 22\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Epoch 1/1024\n",
      "606/606 [==============================] - 52s 78ms/step - loss: 1.2565 - accuracy: 0.4574\n",
      "Epoch 2/1024\n",
      "606/606 [==============================] - 49s 80ms/step - loss: 0.7718 - accuracy: 0.6564\n",
      "Epoch 3/1024\n",
      "606/606 [==============================] - 49s 81ms/step - loss: 1.0027 - accuracy: 0.6185\n",
      "Epoch 4/1024\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 1.8513 - accuracy: 0.4672\n",
      "\n",
      "\n",
      "done.\n",
      "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n",
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/40\n",
      "607/607 [==============================] - 58s 88ms/step - loss: 1.0765 - accuracy: 0.5861 - val_loss: 0.7649 - val_accuracy: 0.6165\n",
      "Epoch 2/40\n",
      "607/607 [==============================] - 54s 87ms/step - loss: 0.6736 - accuracy: 0.6664 - val_loss: 0.6828 - val_accuracy: 0.6582\n",
      "Epoch 3/40\n",
      "607/607 [==============================] - 54s 88ms/step - loss: 0.5980 - accuracy: 0.7051 - val_loss: 0.6391 - val_accuracy: 0.6626\n",
      "Epoch 4/40\n",
      "607/607 [==============================] - 54s 88ms/step - loss: 0.5563 - accuracy: 0.7103 - val_loss: 0.6373 - val_accuracy: 0.6505\n",
      "Epoch 5/40\n",
      "607/607 [==============================] - 54s 89ms/step - loss: 0.5259 - accuracy: 0.7309 - val_loss: 0.6316 - val_accuracy: 0.6440\n",
      "Epoch 6/40\n",
      "607/607 [==============================] - 55s 89ms/step - loss: 0.4866 - accuracy: 0.7421 - val_loss: 0.6236 - val_accuracy: 0.6780\n",
      "Epoch 7/40\n",
      "607/607 [==============================] - 55s 89ms/step - loss: 0.4545 - accuracy: 0.7525 - val_loss: 0.6351 - val_accuracy: 0.6560\n",
      "Epoch 8/40\n",
      "607/607 [==============================] - 55s 89ms/step - loss: 0.4218 - accuracy: 0.7775 - val_loss: 0.6223 - val_accuracy: 0.6835\n",
      "Epoch 9/40\n",
      "607/607 [==============================] - 55s 89ms/step - loss: 0.4103 - accuracy: 0.7787 - val_loss: 0.6413 - val_accuracy: 0.6637\n",
      "Epoch 10/40\n",
      "607/607 [==============================] - 55s 89ms/step - loss: 0.3893 - accuracy: 0.7928 - val_loss: 0.6481 - val_accuracy: 0.6495\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.80      0.81      1295\n",
      "           1       0.59      0.62      0.61       529\n",
      "           2       0.58      0.53      0.56       116\n",
      "           3       0.62      0.64      0.63       107\n",
      "\n",
      "    accuracy                           0.73      2047\n",
      "   macro avg       0.65      0.65      0.65      2047\n",
      "weighted avg       0.73      0.73      0.73      2047\n",
      "\n",
      "\n",
      "Fold  2\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 4\n",
      "\t95percentile : 9\n",
      "\t99percentile : 35\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 3\n",
      "\t95percentile : 9\n",
      "\t99percentile : 30\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 2\n",
      "\t95percentile : 8\n",
      "\t99percentile : 27\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Epoch 1/1024\n",
      "606/606 [==============================] - 53s 80ms/step - loss: 1.2504 - accuracy: 0.5341\n",
      "Epoch 2/1024\n",
      "606/606 [==============================] - 48s 80ms/step - loss: 0.8245 - accuracy: 0.6159\n",
      "Epoch 3/1024\n",
      "606/606 [==============================] - 50s 82ms/step - loss: 1.0868 - accuracy: 0.5927\n",
      "Epoch 4/1024\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 2.2666 - accuracy: 0.4863\n",
      "\n",
      "\n",
      "done.\n",
      "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n",
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/40\n",
      "607/607 [==============================] - 58s 87ms/step - loss: 1.0755 - accuracy: 0.5966 - val_loss: 0.6998 - val_accuracy: 0.6604\n",
      "Epoch 2/40\n",
      "607/607 [==============================] - 53s 86ms/step - loss: 0.7035 - accuracy: 0.6463 - val_loss: 0.6352 - val_accuracy: 0.6835\n",
      "Epoch 3/40\n",
      "607/607 [==============================] - 53s 86ms/step - loss: 0.6256 - accuracy: 0.6926 - val_loss: 0.5842 - val_accuracy: 0.6934\n",
      "Epoch 4/40\n",
      "607/607 [==============================] - 53s 86ms/step - loss: 0.5594 - accuracy: 0.7237 - val_loss: 0.5654 - val_accuracy: 0.7077\n",
      "Epoch 5/40\n",
      "607/607 [==============================] - 53s 86ms/step - loss: 0.5219 - accuracy: 0.7270 - val_loss: 0.5654 - val_accuracy: 0.6978\n",
      "Epoch 6/40\n",
      "607/607 [==============================] - 51s 83ms/step - loss: 0.4824 - accuracy: 0.7501 - val_loss: 0.5270 - val_accuracy: 0.6868\n",
      "Epoch 7/40\n",
      "607/607 [==============================] - 51s 83ms/step - loss: 0.4640 - accuracy: 0.7461 - val_loss: 0.5284 - val_accuracy: 0.6802\n",
      "Epoch 8/40\n",
      "607/607 [==============================] - 51s 83ms/step - loss: 0.4397 - accuracy: 0.7644 - val_loss: 0.5224 - val_accuracy: 0.6890\n",
      "Epoch 9/40\n",
      "607/607 [==============================] - 51s 83ms/step - loss: 0.4254 - accuracy: 0.7638 - val_loss: 0.5448 - val_accuracy: 0.6835\n",
      "Epoch 10/40\n",
      "607/607 [==============================] - 51s 83ms/step - loss: 0.3903 - accuracy: 0.7825 - val_loss: 0.5447 - val_accuracy: 0.6736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84      1405\n",
      "           1       0.58      0.43      0.49       461\n",
      "           2       0.44      0.30      0.36        81\n",
      "           3       0.64      0.38      0.48        99\n",
      "\n",
      "    accuracy                           0.74      2046\n",
      "   macro avg       0.61      0.50      0.54      2046\n",
      "weighted avg       0.72      0.74      0.72      2046\n",
      "\n",
      "\n",
      "Fold  3\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 3\n",
      "\t95percentile : 8\n",
      "\t99percentile : 25\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 3\n",
      "\t95percentile : 9\n",
      "\t99percentile : 35\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 5\n",
      "\t95percentile : 11\n",
      "\t99percentile : 68\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Epoch 1/1024\n",
      "606/606 [==============================] - 52s 77ms/step - loss: 1.2556 - accuracy: 0.4458\n",
      "Epoch 2/1024\n",
      "606/606 [==============================] - 48s 79ms/step - loss: 0.7559 - accuracy: 0.6513\n",
      "Epoch 3/1024\n",
      "606/606 [==============================] - 47s 78ms/step - loss: 1.0405 - accuracy: 0.6222\n",
      "Epoch 4/1024\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 1.3784 - accuracy: 0.5503\n",
      "\n",
      "\n",
      "done.\n",
      "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n",
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/40\n",
      "607/607 [==============================] - 55s 83ms/step - loss: 1.0690 - accuracy: 0.5893 - val_loss: 0.6858 - val_accuracy: 0.6593\n",
      "Epoch 2/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.6786 - accuracy: 0.6642 - val_loss: 0.6006 - val_accuracy: 0.6802\n",
      "Epoch 3/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.5925 - accuracy: 0.7084 - val_loss: 0.5626 - val_accuracy: 0.6934\n",
      "Epoch 4/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.5442 - accuracy: 0.7363 - val_loss: 0.5403 - val_accuracy: 0.6956\n",
      "Epoch 5/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.5027 - accuracy: 0.7419 - val_loss: 0.5392 - val_accuracy: 0.6945\n",
      "Epoch 6/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.4743 - accuracy: 0.7442 - val_loss: 0.5165 - val_accuracy: 0.7055\n",
      "Epoch 7/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.4634 - accuracy: 0.7554 - val_loss: 0.5274 - val_accuracy: 0.7011\n",
      "Epoch 8/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.4194 - accuracy: 0.7823 - val_loss: 0.5059 - val_accuracy: 0.6824\n",
      "Epoch 9/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.4102 - accuracy: 0.7787 - val_loss: 0.5218 - val_accuracy: 0.7044\n",
      "Epoch 10/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.3824 - accuracy: 0.7961 - val_loss: 0.5420 - val_accuracy: 0.7110\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.66      0.75      1252\n",
      "           1       0.57      0.88      0.69       606\n",
      "           2       0.48      0.60      0.53        96\n",
      "           3       0.60      0.37      0.46        92\n",
      "\n",
      "    accuracy                           0.71      2046\n",
      "   macro avg       0.63      0.63      0.61      2046\n",
      "weighted avg       0.76      0.71      0.71      2046\n",
      "\n",
      "\n",
      "Fold  4\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 3\n",
      "\t95percentile : 9\n",
      "\t99percentile : 29\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 3\n",
      "\t95percentile : 9\n",
      "\t99percentile : 37\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 5\n",
      "\t95percentile : 9\n",
      "\t99percentile : 34\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Epoch 1/1024\n",
      "606/606 [==============================] - 52s 77ms/step - loss: 1.2281 - accuracy: 0.5914\n",
      "Epoch 2/1024\n",
      "606/606 [==============================] - 47s 78ms/step - loss: 0.8085 - accuracy: 0.6387\n",
      "Epoch 3/1024\n",
      "606/606 [==============================] - 47s 78ms/step - loss: 0.9722 - accuracy: 0.6334\n",
      "Epoch 4/1024\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 1.7350 - accuracy: 0.5173\n",
      "\n",
      "\n",
      "done.\n",
      "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n",
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/40\n",
      "607/607 [==============================] - 55s 83ms/step - loss: 1.0574 - accuracy: 0.6137 - val_loss: 0.6825 - val_accuracy: 0.6692\n",
      "Epoch 2/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.6658 - accuracy: 0.6888 - val_loss: 0.6198 - val_accuracy: 0.6791\n",
      "Epoch 3/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.5955 - accuracy: 0.7124 - val_loss: 0.5805 - val_accuracy: 0.6967\n",
      "Epoch 4/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.5372 - accuracy: 0.7246 - val_loss: 0.5393 - val_accuracy: 0.7011\n",
      "Epoch 5/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.5099 - accuracy: 0.7480 - val_loss: 0.5316 - val_accuracy: 0.6956\n",
      "Epoch 6/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.4636 - accuracy: 0.7672 - val_loss: 0.5514 - val_accuracy: 0.7022\n",
      "Epoch 7/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.4605 - accuracy: 0.7649 - val_loss: 0.5095 - val_accuracy: 0.7033\n",
      "Epoch 8/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.4302 - accuracy: 0.7719 - val_loss: 0.5635 - val_accuracy: 0.6857\n",
      "Epoch 9/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.4024 - accuracy: 0.7811 - val_loss: 0.5209 - val_accuracy: 0.7000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.67      0.74      1248\n",
      "           1       0.51      0.73      0.60       531\n",
      "           2       0.60      0.47      0.53       196\n",
      "           3       0.45      0.58      0.51        71\n",
      "\n",
      "    accuracy                           0.67      2046\n",
      "   macro avg       0.59      0.61      0.59      2046\n",
      "weighted avg       0.70      0.67      0.67      2046\n",
      "\n",
      "\n",
      "Fold  5\n",
      "preprocessing train...\n",
      "language: en\n",
      "train sequence lengths:\n",
      "\tmean : 4\n",
      "\t95percentile : 10\n",
      "\t99percentile : 35\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Multi-Label? False\n",
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 3\n",
      "\t95percentile : 10\n",
      "\t99percentile : 37\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preprocessing test...\n",
      "language: en\n",
      "test sequence lengths:\n",
      "\tmean : 3\n",
      "\t95percentile : 8\n",
      "\t99percentile : 22\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulating training for different learning rates... this may take a few moments...\n",
      "Epoch 1/1024\n",
      "606/606 [==============================] - 51s 77ms/step - loss: 1.2904 - accuracy: 0.3619\n",
      "Epoch 2/1024\n",
      "606/606 [==============================] - 47s 78ms/step - loss: 0.7503 - accuracy: 0.6464\n",
      "Epoch 3/1024\n",
      "606/606 [==============================] - 47s 78ms/step - loss: 1.0636 - accuracy: 0.6122\n",
      "Epoch 4/1024\n",
      "606/606 [==============================] - 3s 5ms/step - loss: 1.8214 - accuracy: 0.4976\n",
      "\n",
      "\n",
      "done.\n",
      "Please invoke the Learner.lr_plot() method to visually inspect the loss plot to help identify the maximal learning rate associated with falling loss.\n",
      "\n",
      "\n",
      "begin training using onecycle policy with max lr of 2e-05...\n",
      "Epoch 1/40\n",
      "607/607 [==============================] - 55s 83ms/step - loss: 1.0920 - accuracy: 0.5306 - val_loss: 0.6776 - val_accuracy: 0.6582\n",
      "Epoch 2/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.6659 - accuracy: 0.6748 - val_loss: 0.5778 - val_accuracy: 0.6934\n",
      "Epoch 3/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.5689 - accuracy: 0.7179 - val_loss: 0.5449 - val_accuracy: 0.7088\n",
      "Epoch 4/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.5303 - accuracy: 0.7311 - val_loss: 0.5311 - val_accuracy: 0.7066\n",
      "Epoch 5/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.4796 - accuracy: 0.7565 - val_loss: 0.4976 - val_accuracy: 0.7077\n",
      "Epoch 6/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.4530 - accuracy: 0.7590 - val_loss: 0.4958 - val_accuracy: 0.7011\n",
      "Epoch 7/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.4300 - accuracy: 0.7792 - val_loss: 0.4957 - val_accuracy: 0.7066\n",
      "Epoch 8/40\n",
      "607/607 [==============================] - 50s 82ms/step - loss: 0.4186 - accuracy: 0.7764 - val_loss: 0.5112 - val_accuracy: 0.6857\n",
      "Epoch 9/40\n",
      "607/607 [==============================] - 51s 82ms/step - loss: 0.3944 - accuracy: 0.7889 - val_loss: 0.5085 - val_accuracy: 0.7066\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.58      0.70      1223\n",
      "           1       0.52      0.89      0.66       610\n",
      "           2       0.42      0.51      0.46        76\n",
      "           3       0.41      0.33      0.36       137\n",
      "\n",
      "    accuracy                           0.65      2046\n",
      "   macro avg       0.56      0.58      0.55      2046\n",
      "weighted avg       0.72      0.65      0.65      2046\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "count = 1\n",
    "\n",
    "for train_index, test_index in kf.split(word_seq_train):\n",
    "    x_trn, x_tst = word_seq_train[train_index], word_seq_train[test_index]\n",
    "    y_trn, y_tst = y_train_initial[train_index], y_train_initial[test_index]\n",
    "    \n",
    "    x_new_train, x_val, y_new_train, y_val= train_test_split(x_trn, y_trn, test_size=0.11115, random_state=125)\n",
    "    \n",
    "    print(\"\\nFold \", count)\n",
    "    \n",
    "    \n",
    "    \n",
    "    trn = t.preprocess_train(x_new_train, y_new_train)\n",
    "    val = t.preprocess_test(x_val, y_val)\n",
    "    tst= t.preprocess_test(x_tst, y_tst)\n",
    "    \n",
    "    model = t.get_classifier()\n",
    "    \n",
    "    learner = ktrain.get_learner(model, train_data=trn, val_data=val, batch_size=12)\n",
    "    \n",
    "    callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "    \n",
    "    learner.lr_find()\n",
    "     \n",
    "    learner.fit_onecycle(2e-5, 40, callbacks=[callbacks])\n",
    "   \n",
    "    \n",
    "    \n",
    "    learner.validate(val_data=tst, class_names=class_names)\n",
    "    \n",
    "    '''\n",
    "    print(metrics.classification_report(y_tst, y_pred))\n",
    "    \n",
    "    precision = precision_score(y_tst, y_pred, pos_label=1)\n",
    "    recall = recall_score(y_tst, y_pred, pos_label=1)\n",
    "    f1score = f1_score(y_tst, y_pred, pos_label=1)\n",
    "    lstm_accuracy = accuracy_score(y_tst, y_pred)\n",
    "\n",
    "    run_accuracy.append(accuracy)\n",
    "    run_f1score.append(f1score)\n",
    "    run_precision.append(precision)\n",
    "    run_recall.append(recall)\n",
    "    '''\n",
    "    count = count+1\n",
    "    #X_train = data['sourceBeforeFix'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ec683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ee91f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bcafaaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a439476",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc6056a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
